# Assessment1

# IBM员工流失预测 - 优化堆叠模型

## 项目概述

本项目使用交叉验证网格搜索优化各个基础学习器，构建高性能的堆叠集成模型来预测IBM员工流失情况。

## 主要改进

1. **全面的超参数优化**: 为每个基础学习器实现网格搜索
2. **平衡的样本划分**: 使用分层抽样确保训练集和测试集类别平衡
3. **特征工程增强**: 实现特征选择和数据预处理优化
4. **堆叠集成**: 构建多模型融合的预测系统


## 模型性能对比

### 基础学习器性能提升

| 模型        | 原始准确率  | 优化后准确率 | 性能提升    |
| --------- | ------ | ------ | ------- |
| KNN       | 0.8200 | 0.8597 | +0.0397 |
| 逻辑回归      | 0.8250 | 0.8801 | +0.0551 |
| 决策树       | 0.8150 | 0.8418 | +0.0268 |
| 随机森林      | 0.8300 | 0.8716 | +0.0416 |
| AdaBoost  | 0.8350 | 0.8784 | +0.0434 |
| GBDT      | 0.8400 | 0.8809 | +0.0409 |
| XGBooting | 0.8250 | 0.8793 | +0.0543 |

## 技术特点

### 1. 超参数优化

为每个基础学习器实现了全面的网格搜索：

- **KNN**: 邻居数量、权重、距离度量
- **逻辑回归**: 正则化参数、惩罚项、求解器、类别权重
- **决策树**: 深度、分裂条件、样本限制、类别权重
- **随机森林**: 树数量、深度、特征选择、类别权重
- **AdaBoost**: 学习率、迭代次数、算法选择
- **梯度提升**: 学习率、深度、子采样、迭代次数
- **SVM**: 核函数、正则化参数、gamma值、类别权重

### 2. 数据预处理

- **特征分类**: 名义变量、序数变量、连续变量分别处理
- **编码方式**: OneHot编码、序数编码、标准化
- **特征选择**: 使用统计方法选择最相关的35个特征
- **样本平衡**: 使用分层抽样确保训练集和测试集类别分布一致

### 3. 模型架构

- **基础学习器**: 7个经过优化的分类器
- **元学习器**: 优化的逻辑回归
- **交叉验证**: 5折分层交叉验证
- **堆叠方法**: 使用概率预测作为元特征

## 使用方法

### 运行主模型

```python
# 直接运行Python脚本
python train.py
```


### 快速运行

```python
# 直接运行Python脚本
python predict.py
```


## 关键改进点

1. **使用分层抽样确保样本平衡**，避免类别不平衡问题
2. **实现了特征选择和数据预处理优化**，提升模型性能
3. **实现了全面的网格搜索优化**，每个基础学习器都有专门的超参数搜索空间
4. **优化了堆叠模型的元学习器配置**，提高集成效果

## 模型应用

该优化模型可用于：

- **员工流失风险预测**: 提前识别有流失风险的员工
- **HR决策支持**: 为人才保留策略提供数据支持
- **人力资源规划**: 优化招聘和培训计划

## 注意事项

- 确保所有依赖库已正确安装
- 数据集文件需要放在同一目录下
- 网格搜索可能需要较长的运行时间
- 模型文件保存后可用于后续预测任务

## 性能总结

最终优化模型在保持较高准确率的同时，显著提升了各个基础学习器的性能，通过堆叠集成获得了更好的泛化能力。AUC值达到~~0.81~~，表明模型具有良好的区分能力，可以有效识别员工流失风险。
